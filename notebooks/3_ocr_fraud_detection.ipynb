{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8adf6035",
   "metadata": {},
   "source": [
    "# Tâche 3 : Détection de Fraude dans les Documents d'Identité\n",
    "\n",
    "Ce notebook a pour objectif de résoudre la troisième tâche du challenge ANIP : détecter les fraudes et falsifications dans les documents d'identité officiels.\n",
    "\n",
    "## Objectif\n",
    "\n",
    "Développer une IA capable de distinguer automatiquement les documents authentiques des documents falsifiés avec la meilleure précision possible.\n",
    "\n",
    "## Types de Documents Analysés\n",
    "\n",
    "Le dataset contient plusieurs types de documents d'identité :\n",
    "- **Arizona DL** : Permis de conduire d'Arizona (États-Unis)\n",
    "- **ESP** : Documents espagnols\n",
    "- **EST** : Documents estoniens\n",
    "- **RUS** : Documents russes\n",
    "\n",
    "## Classes de Falsification\n",
    "\n",
    "Pour chaque type de document, nous devons classifier :\n",
    "- **Normal** : Documents authentiques\n",
    "- **Forgery 1-4** : Différents types de falsifications\n",
    "\n",
    "## Stratégie Adoptée\n",
    "\n",
    "Notre approche sera systématique et basée sur les meilleures pratiques de détection de fraude :\n",
    "\n",
    "1. **Analyse Exploratoire des Données** : Comprendre la distribution des classes, types de documents, et qualité des images\n",
    "2. **Préparation des Données** : Organisation par type de document et classe, normalisation, augmentation\n",
    "3. **Extraction de Caractéristiques** : Techniques de vision par ordinateur et analyse d'images\n",
    "4. **Modélisation** : Classification multi-classe avec Deep Learning et techniques spécialisées\n",
    "5. **Évaluation** : Métriques de précision, rappel, F1-score par classe et type de document\n",
    "6. **Prédiction Finale** : Application sur les données de test et génération de la soumission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f453a52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importation des bibliothèques fondamentales\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuration des graphiques\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette(\"viridis\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "print(\"Bibliothèques de base importées.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "242bb4c1",
   "metadata": {},
   "source": [
    "## 1. Configuration de l'Environnement\n",
    "\n",
    "Définition des chemins et exploration de la structure des données pour la détection de fraude documentaire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e93c577",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration des chemins de données\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "# Configuration pour l'environnement local\n",
    "DATA_ROOT = Path('/workspaces/anip-facial-ocr-challenge/dataset_tache_3/dataset_tache_3')\n",
    "TRAIN_DIR = DATA_ROOT / 'train'\n",
    "TEST_DIR = DATA_ROOT / 'test'  # Données de test (si disponibles)\n",
    "SUBMISSIONS_DIR = Path('/workspaces/anip-facial-ocr-challenge/submissions')\n",
    "\n",
    "print(\"Configuration des chemins:\")\n",
    "print(f\"   Dataset root: {DATA_ROOT}\")\n",
    "print(f\"   Train directory: {TRAIN_DIR}\")\n",
    "print(f\"   Test directory: {TEST_DIR}\")\n",
    "print(f\"   Submissions: {SUBMISSIONS_DIR}\")\n",
    "\n",
    "# Vérification des chemins\n",
    "train_exists = TRAIN_DIR.exists()\n",
    "test_exists = TEST_DIR.exists()\n",
    "\n",
    "print(f\"\\nVérification:\")\n",
    "print(f\"   Train folder: {'OK' if train_exists else 'MANQUANT'} {TRAIN_DIR}\")\n",
    "print(f\"   Test folder: {'OK' if test_exists else 'MANQUANT'} {TEST_DIR}\")\n",
    "\n",
    "# Exploration de la structure des données d'entraînement\n",
    "if train_exists:\n",
    "    document_types = [d.name for d in TRAIN_DIR.iterdir() if d.is_dir()]\n",
    "    print(f\"\\nTypes de documents trouvés: {document_types}\")\n",
    "    \n",
    "    # Pour chaque type de document, explorer les classes\n",
    "    for doc_type in document_types:\n",
    "        doc_path = TRAIN_DIR / doc_type\n",
    "        classes = [c.name for c in doc_path.iterdir() if c.is_dir()]\n",
    "        print(f\"   {doc_type}: {classes}\")\n",
    "        \n",
    "        # Compter les images dans chaque classe\n",
    "        for class_name in classes:\n",
    "            class_path = doc_path / class_name\n",
    "            image_files = list(class_path.glob('*.png')) + list(class_path.glob('*.jpg')) + list(class_path.glob('*.jpeg'))\n",
    "            print(f\"      {class_name}: {len(image_files)} images\")\n",
    "else:\n",
    "    print(\"   ATTENTION: Les données d'entraînement ne sont pas disponibles\")\n",
    "    document_types = []\n",
    "\n",
    "# Exploration des données de test (si disponibles)\n",
    "if test_exists:\n",
    "    print(f\"\\nExploration des données de test:\")\n",
    "    test_structure = [item.name for item in TEST_DIR.iterdir()]\n",
    "    print(f\"   Structure: {test_structure}\")\n",
    "else:\n",
    "    print(\"\\n   Les données de test ne sont pas encore disponibles localement\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ab44ae",
   "metadata": {},
   "source": [
    "## 2. Analyse Exploratoire des Données (AED)\n",
    "\n",
    "### 2.1 Collecte et Structuration des Métadonnées\n",
    "\n",
    "Nous allons analyser la distribution des documents par type et catégorie (authentique vs falsifié)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a30a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construction du dataset principal\n",
    "print(\"CONSTRUCTION DU DATASET\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "data_list = []\n",
    "\n",
    "if train_exists and document_types:\n",
    "    for doc_type in document_types:\n",
    "        doc_path = TRAIN_DIR / doc_type\n",
    "        \n",
    "        if not doc_path.exists():\n",
    "            continue\n",
    "            \n",
    "        classes = [c.name for c in doc_path.iterdir() if c.is_dir()]\n",
    "        \n",
    "        for class_name in classes:\n",
    "            class_path = doc_path / class_name\n",
    "            \n",
    "            # Recherche des images avec extensions robustes\n",
    "            image_files = []\n",
    "            for ext in ['*.png', '*.jpg', '*.jpeg', '*.PNG', '*.JPG', '*.JPEG']:\n",
    "                image_files.extend(list(class_path.glob(ext)))\n",
    "            \n",
    "            for img_path in image_files:\n",
    "                data_list.append({\n",
    "                    'file_path': str(img_path),\n",
    "                    'filename': img_path.name,\n",
    "                    'document_type': doc_type,\n",
    "                    'class_name': class_name,\n",
    "                    'is_authentic': 1 if class_name == 'normal' else 0,\n",
    "                    'forgery_type': class_name if class_name != 'normal' else 'authentic'\n",
    "                })\n",
    "\n",
    "    # Créer le DataFrame principal\n",
    "    df_train = pd.DataFrame(data_list)\n",
    "    \n",
    "    print(f\"Dataset construit avec succès:\")\n",
    "    print(f\"   Total images: {len(df_train)}\")\n",
    "    print(f\"   Types de documents: {df_train['document_type'].nunique()}\")\n",
    "    print(f\"   Classes: {df_train['class_name'].nunique()}\")\n",
    "    \n",
    "    if len(df_train) > 0:\n",
    "        print(\"\\nAperçu des données:\")\n",
    "        print(df_train.head())\n",
    "        \n",
    "        print(\"\\nDistribution par type de document:\")\n",
    "        print(df_train['document_type'].value_counts())\n",
    "        \n",
    "        print(\"\\nDistribution par classe:\")\n",
    "        print(df_train['class_name'].value_counts())\n",
    "        \n",
    "        print(\"\\nDistribution authentique vs falsifié:\")\n",
    "        print(df_train['is_authentic'].value_counts())\n",
    "        \n",
    "else:\n",
    "    print(\"ATTENTION: Impossible de construire le dataset - données manquantes\")\n",
    "    df_train = pd.DataFrame()\n",
    "\n",
    "# Informations sur le dataset\n",
    "if len(df_train) > 0:\n",
    "    print(f\"\\nInformations détaillées:\")\n",
    "    print(df_train.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e267e7",
   "metadata": {},
   "source": [
    "## 3. Analyse des Fichiers Ground Truth (GT) pour l'OCR\n",
    "\n",
    "### Objectif\n",
    "\n",
    "Les fichiers GT contiennent les annotations OCR de référence pour chaque document. Cette analyse nous permet de :\n",
    "\n",
    "1. **Comprendre la structure des données de sortie** attendues pour la soumission\n",
    "2. **Identifier les champs OCR communs** à tous les types de documents\n",
    "3. **Détecter les champs spécifiques** à chaque pays/type de document\n",
    "4. **Préparer le format de prédiction** pour les données de test\n",
    "\n",
    "### Champs OCR attendus\n",
    "\n",
    "D'après les exemples que nous avons vus :\n",
    "- **Champs d'identité** : `surname`, `given_name`, `birthday`, `gender`\n",
    "- **Champs de document** : `country_code`, `issue_date`, `expire_date`, `card_num`, `personal_num`\n",
    "- **Champs spécifiques** : `second_surname` (ESP), `place_of_birth` (EST), etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b742cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Analyse des fichiers Ground Truth (GT) pour comprendre la structure OCR\n",
    "print(\"ANALYSE DES FICHIERS GROUND TRUTH (GT)\")\n",
    "print(\"=\"*45)\n",
    "\n",
    "gt_data = []\n",
    "all_fields = set()\n",
    "field_by_document = {}\n",
    "\n",
    "if train_exists and document_types:\n",
    "    for doc_type in document_types:\n",
    "        gt_path = TRAIN_DIR / doc_type / 'gt'\n",
    "        \n",
    "        if gt_path.exists():\n",
    "            # Rechercher les fichiers JSON\n",
    "            json_files = list(gt_path.glob('*.json'))\n",
    "            \n",
    "            print(f\"\\n--- {doc_type.upper()} ---\")\n",
    "            print(f\"Fichiers GT trouvés: {len(json_files)}\")\n",
    "            \n",
    "            # Analyser les premiers fichiers pour comprendre la structure\n",
    "            sample_files = json_files[:5]  # Analyser 5 fichiers par type\n",
    "            \n",
    "            for json_file in sample_files:\n",
    "                try:\n",
    "                    with open(json_file, 'r', encoding='utf-8') as f:\n",
    "                        gt_content = json.load(f)\n",
    "                    \n",
    "                    # Stocker pour analyse globale\n",
    "                    gt_data.append({\n",
    "                        'document_type': doc_type,\n",
    "                        'filename': json_file.name,\n",
    "                        'gt_content': gt_content\n",
    "                    })\n",
    "                    \n",
    "                    # Collecter tous les champs\n",
    "                    for field in gt_content.keys():\n",
    "                        all_fields.add(field)\n",
    "                        \n",
    "                        if doc_type not in field_by_document:\n",
    "                            field_by_document[doc_type] = set()\n",
    "                        field_by_document[doc_type].add(field)\n",
    "                    \n",
    "                    # Afficher un exemple\n",
    "                    if json_file == sample_files[0]:  # Premier fichier seulement\n",
    "                        print(f\"\\nExemple GT ({json_file.name}):\")\n",
    "                        for key, value in gt_content.items():\n",
    "                            print(f\"   {key}: '{value}'\")\n",
    "                            \n",
    "                except Exception as e:\n",
    "                    print(f\"Erreur lecture {json_file.name}: {e}\")\n",
    "\n",
    "    print(f\"\\nRÉSUMÉ DE L'ANALYSE:\")\n",
    "    print(f\"Total champs OCR identifiés: {len(all_fields)}\")\n",
    "    print(f\"Champs: {sorted(all_fields)}\")\n",
    "    \n",
    "    # Identifier les champs communs à tous les types de documents\n",
    "    if len(field_by_document) > 1:\n",
    "        common_fields = set.intersection(*field_by_document.values())\n",
    "        print(f\"\\nChamps communs à tous les documents: {sorted(common_fields)}\")\n",
    "        \n",
    "        # Champs spécifiques par type\n",
    "        print(f\"\\nChamps spécifiques par type:\")\n",
    "        for doc_type, fields in field_by_document.items():\n",
    "            specific = fields - common_fields\n",
    "            if specific:\n",
    "                print(f\"   {doc_type}: {sorted(specific)}\")\n",
    "    \n",
    "else:\n",
    "    print(\"Impossible d'analyser les fichiers GT - données manquantes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "223950d8",
   "metadata": {},
   "source": [
    "## 4. Analyse des Propriétés des Images\n",
    "\n",
    "### Objectifs de cette analyse\n",
    "\n",
    "1. **Dimensions et formats** : Comprendre la variabilité des tailles d'images pour le preprocessing\n",
    "2. **Qualité et résolution** : Évaluer la qualité des images pour l'OCR\n",
    "3. **Cohérence par type** : Vérifier si chaque type de document a des caractéristiques communes\n",
    "4. **Preprocessing nécessaire** : Définir les transformations à appliquer\n",
    "\n",
    "### Importance pour l'OCR\n",
    "\n",
    "- **Résolution** : Une résolution insuffisante peut compromettre la lecture des textes\n",
    "- **Dimensions** : Nécessaire pour définir la taille d'entrée des modèles\n",
    "- **Format** : RGB vs Grayscale peut affecter les performances OCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa00727",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(df_train) > 0:\n",
    "    print(\"ANALYSE DES PROPRIÉTÉS DES IMAGES\")\n",
    "    print(\"=\"*40)\n",
    "    \n",
    "    # Échantillonner pour l'analyse (pour éviter de traiter toutes les images)\n",
    "    sample_size = min(100, len(df_train))\n",
    "    sample_df = df_train.sample(n=sample_size, random_state=42)\n",
    "    \n",
    "    image_properties = []\n",
    "    \n",
    "    print(f\"Analyse d'un échantillon de {sample_size} images...\")\n",
    "    \n",
    "    for idx, row in sample_df.iterrows():\n",
    "        try:\n",
    "            img_path = Path(row['file_path'])\n",
    "            \n",
    "            # Lire l'image\n",
    "            img = Image.open(img_path)\n",
    "            img_array = np.array(img)\n",
    "            \n",
    "            # Calculer les propriétés\n",
    "            file_size = img_path.stat().st_size / (1024*1024)  # Taille en MB\n",
    "            \n",
    "            properties = {\n",
    "                'document_type': row['document_type'],\n",
    "                'class_name': row['class_name'],\n",
    "                'width': img.width,\n",
    "                'height': img.height,\n",
    "                'channels': len(img_array.shape),\n",
    "                'mode': img.mode,\n",
    "                'file_size_mb': file_size,\n",
    "                'aspect_ratio': img.width / img.height,\n",
    "                'total_pixels': img.width * img.height\n",
    "            }\n",
    "            \n",
    "            # Statistiques de luminosité\n",
    "            if len(img_array.shape) == 3:  # Image couleur\n",
    "                gray = np.mean(img_array, axis=2)\n",
    "                properties['mean_brightness'] = np.mean(gray)\n",
    "                properties['std_brightness'] = np.std(gray)\n",
    "            else:  # Image grayscale\n",
    "                properties['mean_brightness'] = np.mean(img_array)\n",
    "                properties['std_brightness'] = np.std(img_array)\n",
    "            \n",
    "            image_properties.append(properties)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Erreur analyse {row['filename']}: {e}\")\n",
    "    \n",
    "    # Créer DataFrame des propriétés\n",
    "    props_df = pd.DataFrame(image_properties)\n",
    "    \n",
    "    if len(props_df) > 0:\n",
    "        print(f\"\\nImages analysées avec succès: {len(props_df)}\")\n",
    "        \n",
    "        # Statistiques globales\n",
    "        print(f\"\\nSTATISTIQUES GLOBALES:\")\n",
    "        print(f\"   Largeur - Min: {props_df['width'].min()}, Max: {props_df['width'].max()}, Moyenne: {props_df['width'].mean():.0f}\")\n",
    "        print(f\"   Hauteur - Min: {props_df['height'].min()}, Max: {props_df['height'].max()}, Moyenne: {props_df['height'].mean():.0f}\")\n",
    "        print(f\"   Ratio aspect - Min: {props_df['aspect_ratio'].min():.2f}, Max: {props_df['aspect_ratio'].max():.2f}\")\n",
    "        print(f\"   Taille fichier - Min: {props_df['file_size_mb'].min():.2f}MB, Max: {props_df['file_size_mb'].max():.2f}MB\")\n",
    "        \n",
    "        # Modes d'image\n",
    "        print(f\"\\nMODES D'IMAGE:\")\n",
    "        mode_counts = props_df['mode'].value_counts()\n",
    "        for mode, count in mode_counts.items():\n",
    "            percentage = count / len(props_df) * 100\n",
    "            print(f\"   {mode}: {count} images ({percentage:.1f}%)\")\n",
    "        \n",
    "        # Analyse par type de document\n",
    "        print(f\"\\nANALYSE PAR TYPE DE DOCUMENT:\")\n",
    "        for doc_type in props_df['document_type'].unique():\n",
    "            doc_props = props_df[props_df['document_type'] == doc_type]\n",
    "            print(f\"\\n   --- {doc_type.upper()} ---\")\n",
    "            print(f\"   Dimensions moyennes: {doc_props['width'].mean():.0f} x {doc_props['height'].mean():.0f}\")\n",
    "            print(f\"   Luminosité moyenne: {doc_props['mean_brightness'].mean():.1f}\")\n",
    "            print(f\"   Taille moyenne: {doc_props['file_size_mb'].mean():.2f}MB\")\n",
    "    \n",
    "    else:\n",
    "        print(\"Aucune image analysée avec succès\")\n",
    "        \n",
    "else:\n",
    "    print(\"Pas de données pour analyser les images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c154f8a4",
   "metadata": {},
   "source": [
    "## 5. Visualisation d'Exemples d'Images par Type et Classe\n",
    "\n",
    "### Objectifs\n",
    "\n",
    "1. **Inspection visuelle** : Comprendre les différences entre documents authentiques et falsifiés\n",
    "2. **Qualité OCR** : Évaluer la lisibilité des textes dans les documents\n",
    "3. **Patterns de falsification** : Identifier les caractéristiques visuelles des différents types de fraude\n",
    "4. **Preprocessing** : Définir les techniques de nettoyage et amélioration d'image nécessaires\n",
    "\n",
    "### Ce qu'il faut observer\n",
    "\n",
    "- **Netteté du texte** : Les documents falsifiés peuvent avoir des textes flous ou pixélisés\n",
    "- **Cohérence des polices** : Les falsifications peuvent mélanger différentes polices\n",
    "- **Alignement** : Les informations peuvent être mal alignées dans les falsifications\n",
    "- **Qualité d'impression** : Différences de qualité entre authentiques et falsifiés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4fbf72",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(df_train) > 0:\n",
    "    print(\"VISUALISATION D'EXEMPLES D'IMAGES\")\n",
    "    print(\"=\"*40)\n",
    "    \n",
    "    # Sélectionner des exemples représentatifs\n",
    "    examples_per_type = 2\n",
    "    examples_per_class = 1\n",
    "    \n",
    "    fig, axes = plt.subplots(4, 6, figsize=(20, 16))  # 4 types de documents x 6 classes max\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    plot_idx = 0\n",
    "    \n",
    "    for doc_type in sorted(df_train['document_type'].unique()):\n",
    "        print(f\"\\n--- Exemples pour {doc_type.upper()} ---\")\n",
    "        \n",
    "        doc_data = df_train[df_train['document_type'] == doc_type]\n",
    "        classes = sorted(doc_data['class_name'].unique())\n",
    "        \n",
    "        for class_name in classes:\n",
    "            class_data = doc_data[doc_data['class_name'] == class_name]\n",
    "            \n",
    "            if len(class_data) > 0 and plot_idx < len(axes):\n",
    "                # Prendre le premier exemple de cette classe\n",
    "                example = class_data.iloc[0]\n",
    "                \n",
    "                try:\n",
    "                    img = Image.open(example['file_path'])\n",
    "                    \n",
    "                    # Redimensionner pour l'affichage si nécessaire\n",
    "                    if img.width > 800 or img.height > 600:\n",
    "                        img.thumbnail((800, 600), Image.Resampling.LANCZOS)\n",
    "                    \n",
    "                    axes[plot_idx].imshow(img)\n",
    "                    axes[plot_idx].set_title(f\"{doc_type}\\n{class_name}\", fontsize=10)\n",
    "                    axes[plot_idx].axis('off')\n",
    "                    \n",
    "                    print(f\"   {class_name}: {example['filename']}\")\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    axes[plot_idx].text(0.5, 0.5, f\"Erreur\\n{doc_type}\\n{class_name}\", \n",
    "                                       ha='center', va='center', transform=axes[plot_idx].transAxes)\n",
    "                    axes[plot_idx].axis('off')\n",
    "                    print(f\"   {class_name}: Erreur - {e}\")\n",
    "                \n",
    "                plot_idx += 1\n",
    "    \n",
    "    # Masquer les axes inutilisés\n",
    "    for i in range(plot_idx, len(axes)):\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.suptitle('Exemples d\\'Images par Type de Document et Classe', fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Analyser les différences visuelles observées\n",
    "    print(f\"\\nOBSERVATIONS POUR L'OCR:\")\n",
    "    print(\"=\"*30)\n",
    "    print(\"1. Vérifier la netteté et lisibilité du texte dans chaque type\")\n",
    "    print(\"2. Observer les différences de qualité entre 'normal' et 'forgery_X'\")\n",
    "    print(\"3. Identifier les zones de texte importantes pour l'extraction OCR\")\n",
    "    print(\"4. Noter les variations de format et layout entre types de documents\")\n",
    "    \n",
    "else:\n",
    "    print(\"Pas de données pour la visualisation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6f4721",
   "metadata": {},
   "source": [
    "## 6. Préparation des Données pour l'Entraînement\n",
    "\n",
    "### Stratégie de Modélisation\n",
    "\n",
    "Basé sur notre analyse, nous allons implémenter une approche **hybride OCR + Classification** :\n",
    "\n",
    "1. **Modèle OCR** : Extraire les champs textuels structurés des documents\n",
    "2. **Modèle de Classification** : Détecter si le document est authentique ou falsifié\n",
    "3. **Pipeline intégré** : Combiner les deux approches pour une prédiction complète\n",
    "\n",
    "### Défis identifiés\n",
    "\n",
    "1. **Variabilité des dimensions** : Les documents ont des tailles très différentes (600x375 à 1519x1069)\n",
    "2. **Déséquilibre des classes** : 78.4% de falsifiés vs 21.6% d'authentiques\n",
    "3. **Diversité des formats** : Chaque pays a un layout de document différent\n",
    "4. **Qualité variable** : Certaines falsifications peuvent dégrader la qualité OCR\n",
    "\n",
    "### Plan d'action\n",
    "\n",
    "1. **Normalisation des images** : Redimensionnement et amélioration de qualité\n",
    "2. **Split stratifié** : Maintenir la distribution par type de document et classe\n",
    "3. **Augmentation des données** : Techniques spécifiques pour améliorer la robustesse OCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4ebf7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(df_train) > 0:\n",
    "    print(\"CRÉATION DU SPLIT TRAIN/VALIDATION STRATIFIÉ\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Créer une stratification combinée document_type + class_name\n",
    "    df_train['stratify_key'] = df_train['document_type'] + '_' + df_train['class_name']\n",
    "    \n",
    "    print(\"Groupes de stratification:\")\n",
    "    stratify_counts = df_train['stratify_key'].value_counts()\n",
    "    for group, count in stratify_counts.items():\n",
    "        print(f\"   {group}: {count} images\")\n",
    "    \n",
    "    # Vérifier qu'aucun groupe n'a moins de 2 échantillons (nécessaire pour le split)\n",
    "    min_samples = stratify_counts.min()\n",
    "    if min_samples < 2:\n",
    "        print(f\"\\nATTENTION: Certains groupes ont moins de 2 échantillons (min: {min_samples})\")\n",
    "        print(\"Utilisation d'une stratification simplifiée par document_type seulement\")\n",
    "        stratify_column = df_train['document_type']\n",
    "    else:\n",
    "        stratify_column = df_train['stratify_key']\n",
    "    \n",
    "    # Split 80/20 avec stratification\n",
    "    X = df_train[['file_path', 'filename', 'document_type', 'class_name', 'is_authentic', 'forgery_type']]\n",
    "    y = df_train['is_authentic']  # Target principal: authentique vs falsifié\n",
    "    \n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X, y,\n",
    "        test_size=0.2,\n",
    "        random_state=42,\n",
    "        stratify=stratify_column\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nSplit réalisé:\")\n",
    "    print(f\"   Train: {len(X_train)} images ({len(X_train)/len(df_train)*100:.1f}%)\")\n",
    "    print(f\"   Validation: {len(X_val)} images ({len(X_val)/len(df_train)*100:.1f}%)\")\n",
    "    \n",
    "    # Vérifier la distribution dans chaque ensemble\n",
    "    print(f\"\\nDistribution par type de document:\")\n",
    "    print(\"TRAIN:\")\n",
    "    train_doc_dist = X_train['document_type'].value_counts(normalize=True) * 100\n",
    "    for doc_type, pct in train_doc_dist.items():\n",
    "        print(f\"   {doc_type}: {pct:.1f}%\")\n",
    "    \n",
    "    print(\"VALIDATION:\")\n",
    "    val_doc_dist = X_val['document_type'].value_counts(normalize=True) * 100\n",
    "    for doc_type, pct in val_doc_dist.items():\n",
    "        print(f\"   {doc_type}: {pct:.1f}%\")\n",
    "    \n",
    "    print(f\"\\nDistribution authentique/falsifié:\")\n",
    "    print(f\"TRAIN - Authentiques: {(y_train==1).sum()} ({(y_train==1).mean()*100:.1f}%)\")\n",
    "    print(f\"TRAIN - Falsifiés: {(y_train==0).sum()} ({(y_train==0).mean()*100:.1f}%)\")\n",
    "    print(f\"VAL - Authentiques: {(y_val==1).sum()} ({(y_val==1).mean()*100:.1f}%)\")\n",
    "    print(f\"VAL - Falsifiés: {(y_val==0).sum()} ({(y_val==0).mean()*100:.1f}%)\")\n",
    "    \n",
    "else:\n",
    "    print(\"Pas de données pour créer le split\")\n",
    "    X_train, X_val, y_train, y_val = None, None, None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Train/Validation Split Stratifié\n",
    "\n",
    "Nous devons créer un split intelligent qui préserve :\n",
    "- La distribution des types de documents\n",
    "- La distribution des classes (normal vs forgery_X) \n",
    "- La représentativité de chaque pays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importation des bibliothèques de base pour commencer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(\"Bibliothèques de base importées.\")\n",
    "print(\"Installation des packages PyTorch en cours...\")\n",
    "\n",
    "# Vérifier PyTorch\n",
    "try:\n",
    "    import torch\n",
    "    print(f\"✓ PyTorch disponible - Version: {torch.__version__}\")\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Device: {device}\")\n",
    "except ImportError:\n",
    "    print(\"✗ PyTorch non disponible - sera installé si nécessaire\")\n",
    "    device = 'cpu'\n",
    "\n",
    "print(\"Configuration de base terminée.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bac89e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installation des packages nécessaires\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def install_package(package):\n",
    "    try:\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "        print(f\"✓ {package} installé avec succès\")\n",
    "    except subprocess.CalledProcessError:\n",
    "        print(f\"✗ Erreur lors de l'installation de {package}\")\n",
    "\n",
    "print(\"Installation des packages nécessaires...\")\n",
    "\n",
    "# Packages essentiels pour PyTorch et OCR\n",
    "packages = [\n",
    "    \"torch\",\n",
    "    \"torchvision\", \n",
    "    \"scikit-learn\",\n",
    "    \"pytesseract\",\n",
    "    \"easyocr\"\n",
    "]\n",
    "\n",
    "for package in packages:\n",
    "    try:\n",
    "        __import__(package.replace(\"-\", \"_\"))\n",
    "        print(f\"✓ {package} déjà installé\")\n",
    "    except ImportError:\n",
    "        print(f\"Installation de {package}...\")\n",
    "        install_package(package)\n",
    "\n",
    "print(\"Installation terminée.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da353ba",
   "metadata": {},
   "source": [
    "## Analyse de la Distribution des Classes\n",
    "\n",
    "### Distribution par Type de Document et Classe\n",
    "\n",
    "Cette analyse nous permet de comprendre :\n",
    "1. **L'équilibre des classes** : Y a-t-il plus de documents authentiques que de falsifiés ?\n",
    "2. **La représentation par type de document** : Certains types sont-ils sur ou sous-représentés ?\n",
    "3. **Les types de falsification** : Quels sont les types de fraude les plus courants ?\n",
    "4. **La qualité des données** : Y a-t-il des incohérences ou des problèmes ?\n",
    "\n",
    "### Métriques Importantes\n",
    "\n",
    "- **Ratio Authentique/Falsifié** : Important pour ajuster les métriques d'évaluation\n",
    "- **Distribution par Document** : Arizona DL vs ESP vs EST vs RUS\n",
    "- **Types de Falsification** : Forgery 1, 2, 3, 4 et leurs spécificités\n",
    "- **Taille des Images** : Cohérence des dimensions pour le preprocessing\n",
    "\n",
    "### Stratégie de Modélisation\n",
    "\n",
    "Basé sur cette analyse, nous pourrons décider :\n",
    "- **Approche de classification** : Binaire (authentique/falsifié) ou multi-classe\n",
    "- **Techniques de balancement** : Si les classes sont déséquilibrées\n",
    "- **Architecture de modèle** : CNN spécialisé pour chaque type de document ou modèle global\n",
    "- **Métriques d'évaluation** : Précision, rappel, F1-score adaptés au déséquilibre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ec8ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(df_train) > 0:\n",
    "    # Analyse de la distribution globale\n",
    "    print(\"ANALYSE DE LA DISTRIBUTION DES CLASSES\")\n",
    "    print(\"=\"*45)\n",
    "    \n",
    "    # Distribution par authenticité\n",
    "    auth_dist = df_train['is_authentic'].value_counts()\n",
    "    auth_pct = df_train['is_authentic'].value_counts(normalize=True) * 100\n",
    "    \n",
    "    print(\"Distribution Authentique vs Falsifié:\")\n",
    "    print(f\"   Authentiques: {auth_dist[1]:,} images ({auth_pct[1]:.1f}%)\")\n",
    "    print(f\"   Falsifiés: {auth_dist[0]:,} images ({auth_pct[0]:.1f}%)\")\n",
    "    \n",
    "    # Distribution par type de document\n",
    "    print(f\"\\nDistribution par Type de Document:\")\n",
    "    for doc_type in df_train['document_type'].unique():\n",
    "        count = (df_train['document_type'] == doc_type).sum()\n",
    "        percentage = count / len(df_train) * 100\n",
    "        print(f\"   {doc_type}: {count:,} images ({percentage:.1f}%)\")\n",
    "    \n",
    "    # Distribution par classe détaillée\n",
    "    print(f\"\\nDistribution par Classe:\")\n",
    "    class_dist = df_train['class_name'].value_counts()\n",
    "    for class_name in class_dist.index:\n",
    "        count = class_dist[class_name]\n",
    "        percentage = count / len(df_train) * 100\n",
    "        print(f\"   {class_name}: {count:,} images ({percentage:.1f}%)\")\n",
    "        \n",
    "else:\n",
    "    print(\"Pas de données à analyser - dataset vide\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a87ccb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(df_train) > 0:\n",
    "    # Visualisations de la distribution\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    \n",
    "    # 1. Distribution Authentique vs Falsifié\n",
    "    auth_counts = df_train['is_authentic'].value_counts()\n",
    "    labels = ['Falsifié', 'Authentique']\n",
    "    colors = ['lightcoral', 'lightgreen']\n",
    "    \n",
    "    axes[0, 0].pie(auth_counts.values, labels=labels, autopct='%1.1f%%', colors=colors)\n",
    "    axes[0, 0].set_title('Distribution Authentique vs Falsifié')\n",
    "    \n",
    "    # 2. Distribution par Type de Document\n",
    "    doc_counts = df_train['document_type'].value_counts()\n",
    "    axes[0, 1].bar(doc_counts.index, doc_counts.values, color='skyblue')\n",
    "    axes[0, 1].set_title('Distribution par Type de Document')\n",
    "    axes[0, 1].set_xlabel('Type de Document')\n",
    "    axes[0, 1].set_ylabel('Nombre d\\'Images')\n",
    "    axes[0, 1].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # 3. Distribution par Classe\n",
    "    class_counts = df_train['class_name'].value_counts()\n",
    "    axes[1, 0].bar(class_counts.index, class_counts.values, color='lightsteelblue')\n",
    "    axes[1, 0].set_title('Distribution par Classe')\n",
    "    axes[1, 0].set_xlabel('Classe')\n",
    "    axes[1, 0].set_ylabel('Nombre d\\'Images')\n",
    "    axes[1, 0].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # 4. Heatmap Type de Document vs Classe\n",
    "    cross_tab = pd.crosstab(df_train['document_type'], df_train['class_name'])\n",
    "    sns.heatmap(cross_tab, annot=True, fmt='d', cmap='Blues', ax=axes[1, 1])\n",
    "    axes[1, 1].set_title('Heatmap Document × Classe')\n",
    "    axes[1, 1].set_xlabel('Classe')\n",
    "    axes[1, 1].set_ylabel('Type de Document')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "else:\n",
    "    print(\"Pas de données pour les visualisations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15020b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(df_train) > 0:\n",
    "    # Analyse détaillée par type de document\n",
    "    print(\"ANALYSE DÉTAILLÉE PAR TYPE DE DOCUMENT\")\n",
    "    print(\"=\"*45)\n",
    "    \n",
    "    for doc_type in df_train['document_type'].unique():\n",
    "        print(f\"\\n--- {doc_type.upper()} ---\")\n",
    "        \n",
    "        # Filtrer les données pour ce type de document\n",
    "        doc_data = df_train[df_train['document_type'] == doc_type]\n",
    "        \n",
    "        print(f\"Total images: {len(doc_data)}\")\n",
    "        \n",
    "        # Distribution des classes pour ce type de document\n",
    "        class_dist = doc_data['class_name'].value_counts()\n",
    "        print(\"Distribution des classes:\")\n",
    "        for class_name in class_dist.index:\n",
    "            count = class_dist[class_name]\n",
    "            percentage = count / len(doc_data) * 100\n",
    "            print(f\"   {class_name}: {count} images ({percentage:.1f}%)\")\n",
    "        \n",
    "        # Ratio authentique/falsifié\n",
    "        auth_count = (doc_data['is_authentic'] == 1).sum()\n",
    "        fake_count = (doc_data['is_authentic'] == 0).sum()\n",
    "        \n",
    "        print(f\"Authentiques: {auth_count} ({auth_count/len(doc_data)*100:.1f}%)\")\n",
    "        print(f\"Falsifiés: {fake_count} ({fake_count/len(doc_data)*100:.1f}%)\")\n",
    "        \n",
    "        # Types de falsification\n",
    "        if fake_count > 0:\n",
    "            forgery_types = doc_data[doc_data['is_authentic'] == 0]['forgery_type'].value_counts()\n",
    "            print(\"Types de falsification:\")\n",
    "            for forgery_type in forgery_types.index:\n",
    "                count = forgery_types[forgery_type]\n",
    "                percentage = count / fake_count * 100\n",
    "                print(f\"   {forgery_type}: {count} images ({percentage:.1f}%)\")\n",
    "    \n",
    "    # Analyse de l'équilibre global des classes\n",
    "    print(f\"\\nANALYSE DE L'ÉQUILIBRE DES CLASSES\")\n",
    "    print(\"=\"*40)\n",
    "    \n",
    "    total_authentic = (df_train['is_authentic'] == 1).sum()\n",
    "    total_fake = (df_train['is_authentic'] == 0).sum()\n",
    "    balance_ratio = total_authentic / total_fake if total_fake > 0 else 0\n",
    "    \n",
    "    print(f\"Ratio Authentique/Falsifié: {balance_ratio:.2f}\")\n",
    "    \n",
    "    if balance_ratio > 1.5 or balance_ratio < 0.67:\n",
    "        print(\"ATTENTION: Classes déséquilibrées détectées!\")\n",
    "        print(\"Recommandations:\")\n",
    "        print(\"   - Utiliser des métriques équilibrées (F1-score, AUC-ROC)\")\n",
    "        print(\"   - Considérer des techniques de rééchantillonnage\")\n",
    "        print(\"   - Ajuster les poids des classes dans le modèle\")\n",
    "    else:\n",
    "        print(\"Classes relativement équilibrées\")\n",
    "    \n",
    "    # Analyse de la distribution des fichiers\n",
    "    print(f\"\\nSTATISTIQUES GÉNÉRALES\")\n",
    "    print(\"=\"*25)\n",
    "    print(f\"Types de documents uniques: {df_train['document_type'].nunique()}\")\n",
    "    print(f\"Classes uniques: {df_train['class_name'].nunique()}\")\n",
    "    print(f\"Total d'images: {len(df_train):,}\")\n",
    "    \n",
    "    # Exemples de noms de fichiers pour comprendre la nomenclature\n",
    "    print(f\"\\nExemples de nomenclature:\")\n",
    "    for doc_type in df_train['document_type'].unique()[:2]:\n",
    "        examples = df_train[df_train['document_type'] == doc_type]['filename'].head(3).tolist()\n",
    "        print(f\"   {doc_type}: {examples}\")\n",
    "        \n",
    "else:\n",
    "    print(\"Pas de données pour l'analyse détaillée\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
